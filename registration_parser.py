#!/usr/bin/env python

'''
This script is meant to work with the two files generated by AIS's registration system (more info here: https://www.cfa.harvard.edu/ais/conf/confreg.html)

comment out the functions you don't need, adjust the variable names to be meaningful for your workshop files.
'''


import re
import csv
import os
import datetime

time = datetime.datetime.now().strftime("%B %d at %-I:%M %p")

date = datetime.datetime.now().strftime("%m-%d")
timestamped_directory = "datatables_{0}".format(date)

#if directory does not exist, create it
directory_exists = os.path.isdir("datatables/"+timestamped_directory)
if directory_exists != True:
    make_timestamped_directory_cmd = "mkdir datatables/"+timestamped_directory
    os.system(make_timestamped_directory_cmd)


# ---------------------------------------
#   Create/Open Files
# ---------------------------------------

# wip: making a list of file/page names to loop through and reduce code length

'''
these are all the files and code snippets that need 
updating every time there's a new registrant, most of 
them have their own subroutines for parsing the data. 

You might need to add new ones, and when you do, 
be sure make a new function for it.
'''
''' 
pages_and_files = [
    'last_updated.html',
    'presentations_table.html',
    'abstract_list.txt',
    'cxc_registrants_table.html',
    'all_registrants_table.html',
    'reg_summary_table.html',
    'chandra_summary_table.html',
    'cc_payments_table.html',
    'unpaid_table.html',
    'ciao_isis_table.html',
    'atomDB_table.html',
    'badge_list.html',
    'email_list.html',
    'email_list_file.csv',
    'country_table.html',
    'state_table.html',
    'registration_count.html',
    'expected_income_table.html']

for page in pages_and_files:
    #print page
    #print page.split(".",1)[0]
    #open/create new fiels
    file_handle = page.split(".",1)[0]
    global file_handle
    file_handle = open("test/"+page,"w")
'''




last_updated = open("datatables/"+timestamped_directory+"/last_updated.html","w")
presentations_table = open("datatables/"+timestamped_directory+"/presentations_table.html","w")
abstract_list = open("datatables/"+timestamped_directory+"/abstract_list.txt","w")
cxc_registrants_table = open("datatables/"+timestamped_directory+"/cxc_registrants_table.html","w")
all_registrants_table = open("datatables/"+timestamped_directory+"/all_registrants_table.html","w")
reg_summary_table = open("datatables/"+timestamped_directory+"/reg_summary_table.html","w")
chandra_summary_table = open("datatables/"+timestamped_directory+"/chandra_summary_table.html","w")
cc_payments_table = open("datatables/"+timestamped_directory+"/cc_payments_table.html","w")
unpaid_table = open("datatables/"+timestamped_directory+"/unpaid_table.html","w")
ciao_isis_table = open("datatables/"+timestamped_directory+"/ciao_isis_table.html","w")
atomDB_table = open("datatables/"+timestamped_directory+"/atomDB_table.html","w")
badge_list = open("datatables/"+timestamped_directory+"/badge_list.html","w")
email_list = open("datatables/"+timestamped_directory+"/email_list.html","w")
email_list_file = open("datatables/"+timestamped_directory+"/email_list_file.csv","w")
country_table = open("datatables/"+timestamped_directory+"/country_table.html","w")
state_table = open("datatables/"+timestamped_directory+"/state_table.html","w")
registration_count = open("datatables/"+timestamped_directory+"/registration_count.html","w")
expected_income_table = open("datatables/"+timestamped_directory+"/expected_income_table.html","w")



# function to collect all registrants
def all_registrants_counter(d):
    all_registrants_table.write(
        "<tr><td> " + d['f_name'] + " " + d['l_name'] + " " +
        "</td><td> " + d['chandra'] + " " +
        "</td><td> " + d['reg_total'] + " " +
        "</td><td> " + d['user_id'] + " " +
        "</td><td> " + d['country'] + " " +
        "</td></tr>\n")

# function to collect the cxc registrants
def cxc_registrants_counter(d):
    if row[15] == "SAO" or row[15] == "SUB":
        cxc_registrants_table.write(
            "<tr><td> " + d['f_name'] + " " + d['l_name'] + " " +
            "</td><td> " + d['chandra'] + " " +
            "</td><td> " + d['reg_total'] + " " +
            "</td><td> " + d['user_id'] + " " +
            "</td></tr>\n")

# function to collect the abstracts
def presentations_counter(d):
    if row[19] != "None":
        presentations_table.write(
            "<tr><td> " + d['f_name'] + " " + d['l_name'] + " " +
            "</td><td> " + d['pres_type'] + " " +
            "</td><td> " + d['pres_title'] + " " +
            "</td></tr>\n")
        abstract_list.write("""
Author First Name: {0}
Author Last Name: {1}
Email Address: {2}
Institution: {3}
Presentation: {4}
Title: {5}
Abstract: {6}
Comments: {7}
Status: Submitted

""".format(row[1],row[3],row[12],row[13],row[19],row[20],row[21],row[22]))



# function to count types of registrants
standard_registrants_count = 0
student_registrants_count = 0
staff_count = 0
def reg_summary_counter(d):
    global standard_registrants_count, student_registrants_count, staff_count
    if d['reg_total'] == "120":
        standard_registrants_count += 1
    if d['reg_total'] == "100":
        student_registrants_count += 1
    if d['reg_total'] == "0":
        staff_count += 1
    return standard_registrants_count, student_registrants_count, staff_count

# function to count the survey responses
sao_count = 0
sub_count = 0
nasa_count = 0
other_count = 0
def chandra_summary_counter(d):
    global sao_count, sub_count, nasa_count, other_count
    if d['chandra'] == "SAO":
        sao_count += 1
    if d['chandra'] == "SUB":
        sub_count += 1
    if d['chandra'] == "NASA":
        nasa_count += 1
    if d['chandra'] == "NONE":
        other_count += 1
    return sao_count, sub_count, nasa_count, other_count

def ciao_isis_workshop_counter(d):
    if d['CI_wrkshp'] == "Yes":
        ciao_isis_table.write(
            "<tr><td> " + d['f_name'] + " " + d['l_name'] + " " +
            "</td><td> " + d['email'] + " " +
            "</td><td> " + d['reg_total'] + " " +
            "</td></tr>")

def atomDB_workshop_counter(d):
    if d['ADB_wrkshp'] == "Yes":
        atomDB_table.write(
            "<tr><td> " + d['f_name'] + " " + d['l_name'] + " " +
            "</td><td> " + d['email'] + " " +
            "</td><td> " + d['reg_total'] + " " +
            "</td></tr>")

def badge_names(d):
    badge_list.write(
        "<p><span class='bold'>" + d['f_name'] + " " + d['l_name'] + 
        "</span><br />" + d['instit'] + "</p>")

def get_emails(d):
    email_list.write( d['email'] + "<br />")
    email_list_file.write( d['email'] + ",")

states = {}
countries = {}
def get_demographics(d):
    #print row[7]
    if d['state'] == "NOTNA": #add functionality to skip "NOTNA" states
        print ""
    elif d['state'] in states:
        states[d['state']] += 1
    else:
        states[d['state']] = 1

    #if (
        #d['country'] == "United States" or 
       # d['country'] == "United States of America" or 
      #  d['country'] == "US"
     #   ):
        #print "shortening to USA"
    #    countries['USA'] += 1
    if d['country'] in countries: #add functionality to combine USA/United States
        countries[d['country']] += 1
    else:
        countries[d['country']] = 1
        
    return states, countries

# ----------------------------------------------------------------------------
# ----------------------------------------------------------------------------
#   Run all analysis 
# ----------------------------------------------------------------------------
# ----------------------------------------------------------------------------

'''
!IMPORTANT!
Be sure you re-calibrate the key-value pairs in reg_dict to match your incoming data!
'''

with open('hrxs15.txt') as reg_file:
    reg_tsv = csv.reader(reg_file, delimiter='\t')
    for row in reg_tsv:
        #print row[8].replace('The ','')
        if (
            row[8] == "United States" or 
            row[8] == "United States of America" or 
            row[8] == "US"
        ):
            row[8] = "USA"
        reg_dict = {"salutation":row[0],
                    "f_name":row[1],
                    "m_init":row[2],
                    "l_name":row[3],
                    "add_l1":row[4],
                    "add_l2":row[5],
                    "city": row[6],
                    "state":row[7],
                    "country":row[8].replace('The ',''),
                    "zipcode" :row[9],
                    "hme_phn": row[10],
                    "wrk_phn": row[11],
                    "email":row[12],
                    "instit": row[13],
                    "badge": row[14],
                    "chandra": row[15],
                    "CI_wrkshp": row[16],
                    "ADB_wrkshp": row[17],
                    "assist": row[18],
                    "pres_type": row[19],
                    "pres_title": row[20],
                    "abstract": row[21],
                    "comments": row[22],
                    "reg_total": row[23],
                    "reg_standard": row[24],
                    "reg_student": row[25],
                    "reg_support": row[26],
                    "user_id": row[27],
                    "pay_method": row[28]}
        # count the cxc registrants
        all_registrants_counter(reg_dict)
        # count the cxc registrants
        cxc_registrants_counter(reg_dict)
        # gather the presentations/abstracts
        presentations_counter(reg_dict)
        # count the types of registrants
        reg_summary_counter(reg_dict)
        # parse the chandra summary data
        chandra_summary_counter(reg_dict)
        # ciao/isis workshop count
        ciao_isis_workshop_counter(reg_dict)
        # atomDB workshop count
        atomDB_workshop_counter(reg_dict)
        # gather badge names list
        badge_names(reg_dict)
        # gather emails
        get_emails(reg_dict)
        #count countries
        get_demographics(reg_dict)
            



# function to count the survey responses
early_standard_registration = 0
student_registration = 0
standard_registration = 0
def income_calculator(d):
    global early_standard_registration, student_registration, standard_registration
    if d['amt_paid'] == "SAO":
        early_standard_registration += 1
    if d['amt_paid'] == "SUB":
        student_registration += 1
    if d['amt_paid'] == "NASA":
        standard_registration += 1


# ----------------------------------------------------------------------------
#   Run credit card analysis 
# ----------------------------------------------------------------------------
with open('hrxs15paidcc.txt') as paid_file:
    paid_tsv = csv.reader(paid_file, delimiter='\t')
    for row in paid_tsv:
        paid_dict = {"l_name":row[0],
                     "f_name":row[1],
                     "user_id": row[2],
                     "amt_paid": row[3],
                     "pay_meth":row[4],
                     "successful":row[5],
                     "timestamp": row[6]}
        cc_payments_table.write(
            "<tr><td> " + paid_dict['f_name'] + " " + paid_dict['l_name'] + " " + 
            "</td><td> " + paid_dict['user_id'] + " " + 
            "</td><td> " + paid_dict['amt_paid'] + " " + 
            "</td><td> " + paid_dict['successful'] + " " + 
            "</td><td> " + paid_dict['timestamp'] + " " + 
            "</td></tr>")
        if paid_dict['successful'] != "ACCEPT":
            unpaid_table.write(
            "<tr><td> " + paid_dict['f_name'] + " " + paid_dict['l_name'] +
            "</td><td> " + paid_dict['user_id'] + " " + 
            "</td><td> " + paid_dict['amt_paid'] + " " + 
            "</td><td> " + paid_dict['successful'] + " " + 
            "</td><td> " + paid_dict['timestamp'] + " " + 
            "</td></tr>")
        income_calculator(paid_dict)




#print states

for state, number in states.items():
    state_table.write(
        "<tr><td> " + str(state) + 
        "</td><td> " + str(number) + 
        "</td></tr>")

for country, number in countries.items():
    country_table.write(
        "<tr><td> " + str(country) + 
        "</td><td> " + str(number) + 
        "</td></tr>")

last_updated.write("<span> " + str(time) + " </span>")

total_count = standard_registrants_count + student_registrants_count + staff_count

registration_count.write(" Total: "+str(total_count))

reg_summary_table.write(
    "<tr><td> " + str(standard_registrants_count) +
    "</td><td> " + str(student_registrants_count) +
    "</td><td> " + str(staff_count) + 
    "</td></tr>")

chandra_summary_table.write(
    "<tr><td> " + str(sao_count) +
    "</td><td> " + str(sub_count) +
    "</td><td> " + str(nasa_count) +
    "</td><td> " + str(other_count) +
    "</td></tr>")





# ---------------------------------------
#   Close Files
# ---------------------------------------
'''
for page in pages_and_files:
    #print page
    #print page.split(".",1)[0]
    #open/create new fiels
    file_handle = page.split(".",1)[0]
    file_handle.close()
'''

last_updated.close()
presentations_table.close()
abstract_list.close()
cxc_registrants_table.close()
all_registrants_table.close()
reg_summary_table.close()
chandra_summary_table.close()
cc_payments_table.close()
unpaid_table.close()
ciao_isis_table.close()
atomDB_table.close()
badge_list.close()
email_list.close()
email_list_file.close()
state_table.close()
country_table.close()
registration_count.close()
expected_income_table.close()


#wymanRep_copy_cmd = "cp datatables/"+timestamped_directory+ "/*.* /data/cdoweb/wymanRep/cdo/hrxs2015/admin/data/"
#retvalue = os.system(wymanRep_copy_cmd)
#if retvalue == 0:
#    print "Datatables copied successfully to wymanRep"


prev_copy_cmd = "cp datatables/"+timestamped_directory+ "/*.* /proj/web-cxc-dmz-prev/htdocs/cdo/hrxs2015/admin/data/"
retvalue = os.system(prev_copy_cmd)
if retvalue == 0:
    print "Datatables copied successfully to preview server"


live_copy_cmd = "cp datatables/"+timestamped_directory+ "/*.* /proj/web-cxc-dmz/htdocs/cdo/hrxs2015/admin/data/"
retvalue = os.system(live_copy_cmd)
if retvalue == 0:
    print "Datatables copied successfully to live server"

#use os.system to automatically run the abstract parser script

